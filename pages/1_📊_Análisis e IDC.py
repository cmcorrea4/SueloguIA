"""
P√°gina de Estad√≠sticos y Calidad de Datos
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import importlib

import utils          
import calidad_datos
import visualizaciones

importlib.reload(utils)
importlib.reload(calidad_datos)
importlib.reload(visualizaciones)

# Agregar path del proyecto
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import VARIABLES_ESTADISTICAS, preparar_dataframe_numerico
from calidad_datos import calcular_indice_calidad_datos, generar_recomendaciones
from visualizaciones import calcular_estadisticos, crear_histogramas, crear_boxplots, crear_matriz_correlacion

st.set_page_config(page_title="Estad√≠sticos", page_icon="üìä", layout="wide")

st.title("üìä An√°lisis Estad√≠stico de Variables")

# Verificar que hay datos cargados
if 'df_original' not in st.session_state or st.session_state.df_original is None:
    st.warning("‚ö†Ô∏è No hay datos cargados. Por favor ve a la p√°gina de Inicio para cargar datos.")
    st.stop()

df = st.session_state.df_original

# Encontrar variables disponibles
vars_disponibles = [v for v in VARIABLES_ESTADISTICAS if v in df.columns]
vars_no_disponibles = [v for v in VARIABLES_ESTADISTICAS if v not in df.columns]

if not vars_disponibles:
    st.error("‚ùå No se encontraron las variables especificadas en el dataset")
    st.info("Las columnas disponibles en tu dataset son:")
    st.write(list(df.columns))
    st.stop()

st.success(f"‚úÖ Se encontraron {len(vars_disponibles)} de {len(VARIABLES_ESTADISTICAS)} variables")

if vars_no_disponibles:
    with st.expander("‚ö†Ô∏è Variables no encontradas en el dataset"):
        for var in vars_no_disponibles:
            st.write(f"- {var}")

# ============================================================================
# CONFIGURACI√ìN DE AN√ÅLISIS
# ============================================================================

st.subheader("üîß Configuraci√≥n de an√°lisis")

# Inicializar el key del multiselect si no existe
if 'ms_variables' not in st.session_state:
    st.session_state.ms_variables = []

# Limpiar variables que ya no existen en el dataset actual
st.session_state.ms_variables = [
    v for v in st.session_state.ms_variables 
    if v in vars_disponibles
]

col1, col2 = st.columns([3, 1])

with col1:
    # Multiselect usando key directamente (Streamlit maneja el estado)
    variables_seleccionadas = st.multiselect(
        "Selecciona variables para analizar:",
        options=vars_disponibles,
        key="ms_variables",
        help="Selecciona las variables que deseas incluir en el an√°lisis"
    )
    
    metodo_outliers = st.selectbox(
        "üéØ M√©todo de detecci√≥n de outliers para ICD:",
        options=['iqr', 'kmeans', 'svm', 'combinado'],
        format_func=lambda x: {
            'iqr': 'üìä IQR (Cuartiles) - Tradicional',
            'kmeans': 'üéØ K-means - Clustering',
            'svm': 'ü§ñ SVM - One-Class',
            'combinado': 'üîÑ Combinado (suma de los 3)'
        }[x],
        help="Selecciona el m√©todo para calcular la dimensi√≥n de Precisi√≥n en el ICD"
    )

with col2:
    st.write("")
    st.write("")
    
    # Usar callback para seleccionar todas
    def seleccionar_todas():
        st.session_state.ms_variables = vars_disponibles.copy()
    
    def deseleccionar_todas():
        st.session_state.ms_variables = []
    
    st.button("‚úÖ Seleccionar Todas", use_container_width=True, on_click=seleccionar_todas)
    st.button("‚ùå Deseleccionar", use_container_width=True, on_click=deseleccionar_todas)
    
    analizar_btn = st.button("üìà Generar An√°lisis", type="primary", use_container_width=True)

# ============================================================================
# AN√ÅLISIS
# ============================================================================

if analizar_btn and variables_seleccionadas:
    with st.spinner("üìä Generando an√°lisis..."):
        stats_df = calcular_estadisticos(df, variables_seleccionadas)
        
        if stats_df is not None:
            st.divider()
            
            # SECCI√ìN 1: Estad√≠sticos descriptivos
            st.subheader("üìã Estad√≠sticos Descriptivos")
            
            stats_display = stats_df.copy()
            numeric_columns = ['Media', 'Mediana', 'Desv. Std', 'M√≠nimo', 'Q1 (25%)', 'Q3 (75%)', 'M√°ximo', 'Rango', 'CV (%)', 'Asimetr√≠a', 'Curtosis']
            for col in numeric_columns:
                if col in stats_display.columns:
                    stats_display[col] = stats_display[col].round(3)
            
            st.info("üí° **Detecci√≥n de Outliers por 3 m√©todos:** IQR (Cuartiles), K-means (Clustering), SVM (One-Class)")
            
            st.dataframe(stats_display, use_container_width=True, hide_index=True, height=400)
            
            # An√°lisis de outliers
            if 'Total Outliers' in stats_display.columns:
                total_outliers_sum = stats_display['Total Outliers'].sum()
                if total_outliers_sum > 0:
                    st.warning(f"‚ö†Ô∏è **Total de outliers detectados (suma de 3 m√©todos): {int(total_outliers_sum)}**")
                    
                    top_outliers = stats_display.nlargest(5, 'Total Outliers')[['Variable', 'Outliers IQR', 'Outliers K-means', 'Outliers SVM', 'Total Outliers']]
                    if len(top_outliers) > 0:
                        st.markdown("**üîç Variables con m√°s outliers detectados:**")
                        st.dataframe(top_outliers, use_container_width=True, hide_index=True)
                else:
                    st.success("‚úÖ No se detectaron outliers significativos")
            
            csv = stats_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Descargar estad√≠sticos como CSV",
                data=csv,
                file_name="estadisticos_variables.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            st.divider()
            
            # SECCI√ìN 2: √çNDICE DE CALIDAD DE DATOS
            st.subheader("üéØ √çndice de Calidad de Datos (ICD)")
            
            with st.spinner("Calculando √≠ndice de calidad..."):
                resultado_icd = calcular_indice_calidad_datos(
                    df=df,
                    variables_numericas=variables_seleccionadas,
                    columnas_esperadas=VARIABLES_ESTADISTICAS,
                    metodo_outliers=metodo_outliers
                )
            
            # M√©trica principal
            st.markdown("### üìä Calidad General")
            col_metric1, col_metric2, col_metric3 = st.columns([2, 1, 1])
            
            with col_metric1:
                icd_total = resultado_icd['icd_total']
                nivel = resultado_icd['nivel_calidad']
                emoji = resultado_icd['emoji']
                
                st.markdown(f"""
                <div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                            border-radius: 10px;'>
                    <h1 style='margin: 0; font-size: 60px; color: white;'>{emoji} {icd_total:.1f}</h1>
                    <h3 style='margin: 10px 0 0 0; color: white;'>Calidad {nivel}</h3>
                    <p style='margin: 5px 0 0 0; opacity: 0.9; color: white;'>sobre 100 puntos</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_metric2:
                st.metric("Variables analizadas", len(variables_seleccionadas))
                completitud_pct = resultado_icd['detalles']['completitud']['pct_completo']
                st.metric("Completitud", f"{completitud_pct:.1f}%")
            
            with col_metric3:
                unicidad_pct = resultado_icd['detalles']['unicidad']['pct_registros_unicos']
                st.metric("Unicidad", f"{unicidad_pct:.1f}%")
                precision_pct = resultado_icd['detalles']['precision']['pct_datos_precisos']
                st.metric("Precisi√≥n", f"{precision_pct:.1f}%")
            
            st.markdown("---")
            
            # Desglose por dimensiones
            st.markdown("### üìà Desglose por Dimensiones")
            
            col1, col2, col3 = st.columns(3)
            desglose = resultado_icd['desglose']
            
            with col1:
                st.metric("üîµ Completitud", f"{desglose['Completitud (25pts)']:.1f} / 25")
                st.metric("üü£ Unicidad", f"{desglose['Unicidad (15pts)']:.1f} / 15")
            
            with col2:
                st.metric("üü¢ Consistencia", f"{desglose['Consistencia (15pts)']:.1f} / 15")
                st.metric("üü° Precisi√≥n", f"{desglose['Precisi√≥n (20pts)']:.1f} / 20")
            
            with col3:
                st.metric("üü† Variabilidad", f"{desglose['Variabilidad (15pts)']:.1f} / 15")
                st.metric("üî¥ Integridad", f"{desglose['Integridad (10pts)']:.1f} / 10")
            
            st.markdown("---")
            
            # M√©tricas detalladas
            st.markdown("### üîç M√©tricas Detalladas")
            
            tab_comp, tab_uni, tab_prec, tab_var = st.tabs([
                "üìä Completitud", "üîÑ Unicidad", "üéØ Precisi√≥n (Outliers)", "üìâ Variabilidad"
            ])
            
            with tab_comp:
                detalles_comp = resultado_icd['detalles']['completitud']
                
                col1, col2, col3 = st.columns(3)
                col1.metric("Valores totales", f"{detalles_comp['total_valores']:,}")
                col2.metric("Valores nulos", f"{detalles_comp['total_nulos']:,}")
                col3.metric("Completitud", f"{detalles_comp['pct_completo']:.1f}%")
                
                if detalles_comp['columnas_problematicas']:
                    st.warning("‚ö†Ô∏è **Columnas con >50% de valores nulos:**")
                    df_prob = pd.DataFrame([
                        {'Columna': col, '% Nulos': f"{pct:.1f}%"} 
                        for col, pct in detalles_comp['columnas_problematicas'].items()
                    ])
                    st.dataframe(df_prob, use_container_width=True, hide_index=True)
                else:
                    st.success("‚úÖ Todas las columnas tienen menos del 50% de valores nulos")
            
            with tab_uni:
                detalles_uni = resultado_icd['detalles']['unicidad']
                
                col1, col2, col3 = st.columns(3)
                col1.metric("Total filas", f"{len(df):,}")
                col2.metric("Filas duplicadas", f"{detalles_uni['filas_duplicadas']:,}")
                col3.metric("Unicidad", f"{detalles_uni['pct_registros_unicos']:.1f}%")
                
                if detalles_uni['filas_duplicadas'] > 0:
                    st.warning(f"‚ö†Ô∏è Se detectaron **{detalles_uni['filas_duplicadas']}** filas duplicadas")
                else:
                    st.success("‚úÖ No hay filas duplicadas")
            
            with tab_prec:
                detalles_prec = resultado_icd['detalles']['precision']
                metodo_usado = detalles_prec.get('metodo_usado', 'iqr')
                
                metodo_nombre = {
                    'iqr': 'üìä IQR (Cuartiles)',
                    'kmeans': 'üéØ K-means',
                    'svm': 'ü§ñ SVM (One-Class)',
                    'combinado': 'üîÑ Combinado (3 m√©todos)'
                }.get(metodo_usado, metodo_usado)
                
                st.info(f"**M√©todo usado para ICD:** {metodo_nombre}")
                
                col1, col2, col3 = st.columns(3)
                col1.metric("Datos num√©ricos", f"{detalles_prec['total_datos_numericos']:,}")
                col2.metric("Outliers detectados", f"{detalles_prec['total_outliers']:,}")
                col3.metric("Precisi√≥n", f"{detalles_prec['pct_datos_precisos']:.1f}%")
                
                if detalles_prec['outliers_por_columna']:
                    st.warning(f"‚ö†Ô∏è **Variables con outliers detectados:**")
                    
                    outliers_data = []
                    for col, info in detalles_prec['outliers_por_columna'].items():
                        row = {
                            'Variable': col,
                            'Outliers': info['cantidad'],
                            '% Outliers': f"{info['porcentaje']:.2f}%"
                        }
                        
                        if metodo_usado == 'combinado':
                            row.update({
                                'Outliers IQR': info.get('outliers_iqr', 0),
                                'Outliers K-means': info.get('outliers_kmeans', 0),
                                'Outliers SVM': info.get('outliers_svm', 0),
                            })
                        
                        outliers_data.append(row)
                    
                    df_outliers = pd.DataFrame(outliers_data)
                    st.dataframe(df_outliers, use_container_width=True, hide_index=True)
                    
                    # DataFrame completo con filas de outliers
                    st.markdown("---")
                    st.markdown("#### üìã Filas Completas con Outliers")
                    
                    df_outliers_full = detalles_prec.get('df_outliers_completo', pd.DataFrame())
                    num_filas_outliers = detalles_prec.get('num_filas_con_outliers', 0)
                    
                    if not df_outliers_full.empty:
                        st.markdown(f"**Total de filas con al menos un outlier: {num_filas_outliers}**")
                        st.dataframe(df_outliers_full, use_container_width=True, height=400)
                        
                        csv_outliers = df_outliers_full.to_csv(index=True).encode('utf-8')
                        st.download_button(
                            label="üì• Descargar filas con outliers (CSV)",
                            data=csv_outliers,
                            file_name=f"outliers_completos_{metodo_usado}.csv",
                            mime="text/csv"
                        )
                else:
                    st.success("‚úÖ No se detectaron outliers significativos")
            
            with tab_var:
                detalles_var = resultado_icd['detalles']['variabilidad']
                
                col1, col2 = st.columns(2)
                col1.metric("CV Promedio", f"{detalles_var['cv_promedio']:.1f}%")
                col2.metric("% Variables CV adecuado", f"{detalles_var['pct_variabilidad_adecuada']:.1f}%")
                
                if detalles_var['cv_por_columna']:
                    st.markdown("**üìä Coeficiente de Variaci√≥n:**")
                    
                    cv_data = []
                    for col, cv in detalles_var['cv_por_columna'].items():
                        if abs(cv) < 10:
                            categoria, emoji_cv = "Baja", "üü¢"
                        elif abs(cv) < 50:
                            categoria, emoji_cv = "Moderada", "üü°"
                        elif abs(cv) < 100:
                            categoria, emoji_cv = "Alta", "üü†"
                        else:
                            categoria, emoji_cv = "Muy Alta", "üî¥"
                        
                        cv_data.append({'Variable': col, 'CV (%)': f"{cv:.2f}", 'Categor√≠a': f"{emoji_cv} {categoria}"})
                    
                    df_cv = pd.DataFrame(cv_data)
                    st.dataframe(df_cv, use_container_width=True, hide_index=True)
            
            st.markdown("---")
            
            # Recomendaciones
            st.markdown("### üí° Recomendaciones")
            recomendaciones = generar_recomendaciones(resultado_icd)
            for rec in recomendaciones:
                st.markdown(rec)
            
            st.markdown("---")
            
            # Interpretaci√≥n final
            st.markdown("### üìù Interpretaci√≥n Final")
            
            if icd_total >= 90:
                st.success(f"**{emoji} Excelente calidad ({icd_total:.1f}/100)** - Datos listos para an√°lisis avanzados.")
            elif icd_total >= 75:
                st.info(f"**{emoji} Buena calidad ({icd_total:.1f}/100)** - Utilizables con limpieza menor.")
            elif icd_total >= 60:
                st.warning(f"**{emoji} Calidad aceptable ({icd_total:.1f}/100)** - Requiere limpieza antes de an√°lisis.")
            elif icd_total >= 40:
                st.warning(f"**{emoji} Calidad baja ({icd_total:.1f}/100)** - Limpieza profunda requerida.")
            else:
                st.error(f"**{emoji} Calidad cr√≠tica ({icd_total:.1f}/100)** - Revisar proceso de captura.")
            
            st.divider()
            
            # SECCI√ìN 3: Visualizaciones
            st.subheader("üìä Visualizaciones")
            
            viz_tab1, viz_tab2, viz_tab3 = st.tabs(["üìä Histogramas", "üì¶ Boxplots", "üî• Correlaciones"])
            
            with viz_tab1:
                st.markdown("#### Distribuci√≥n de Variables")
                fig_hist = crear_histogramas(df, variables_seleccionadas)
                if fig_hist:
                    st.plotly_chart(fig_hist, use_container_width=True)
                else:
                    st.warning("No se pudieron generar histogramas")
            
            with viz_tab2:
                st.markdown("#### Detecci√≥n de Valores At√≠picos")
                fig_box = crear_boxplots(df, variables_seleccionadas)
                if fig_box:
                    st.plotly_chart(fig_box, use_container_width=True)
                else:
                    st.warning("No se pudieron generar boxplots")
            
            with viz_tab3:
                st.markdown("#### Relaciones entre Variables")
                if len(variables_seleccionadas) >= 2:
                    fig_corr = crear_matriz_correlacion(df, variables_seleccionadas)
                    if fig_corr:
                        st.plotly_chart(fig_corr, use_container_width=True)
                        
                        df_numeric = preparar_dataframe_numerico(df, variables_seleccionadas)
                        
                        if len(df_numeric.columns) >= 2:
                            corr_matrix = df_numeric.corr()
                            
                            correlaciones = []
                            for i in range(len(corr_matrix.columns)):
                                for j in range(i+1, len(corr_matrix.columns)):
                                    corr_val = corr_matrix.iloc[i, j]
                                    if not pd.isna(corr_val):
                                        correlaciones.append({
                                            'Variable 1': corr_matrix.columns[i],
                                            'Variable 2': corr_matrix.columns[j],
                                            'Correlaci√≥n': corr_val
                                        })
                            
                            if correlaciones:
                                df_corr = pd.DataFrame(correlaciones)
                                df_corr['Correlacion_abs'] = df_corr['Correlaci√≥n'].abs()
                                df_corr = df_corr.sort_values('Correlacion_abs', ascending=False)
                                
                                st.markdown("##### Top 10 Correlaciones m√°s Fuertes")
                                st.dataframe(
                                    df_corr.head(10)[['Variable 1', 'Variable 2', 'Correlaci√≥n']].round(3),
                                    use_container_width=True, hide_index=True
                                )
                    else:
                        st.warning("No se pudo generar la matriz de correlaci√≥n")
                else:
                    st.info("Selecciona al menos 2 variables para ver correlaciones")
        
        else:
            st.error("‚ùå No se pudieron calcular estad√≠sticos. Verifica que las variables sean num√©ricas.")

elif analizar_btn:
    st.warning("‚ö†Ô∏è Por favor selecciona al menos una variable para analizar")
